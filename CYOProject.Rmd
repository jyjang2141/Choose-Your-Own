---
title: "CYOProject"
author: "Joon Young Jang"
date: "2024-03-17"
output: pdf_document
bibliography: citations.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

Consumer reviews are an important part of the e-commerce experience and their impact on consumer behavior is notable. That is, while positive reviews may encourage the consumers to purchase an item, negative reviews may forestall that decision. This report therefore will use a publicly available dataset to predict consumer ratings of items from Sephora, a personal care product retailer. The data archive collected and assembled by Raghad Alharb contains 9169 rows (9168 items total) and 21 columns offering relevant information for each item. To prevent overfitting, 80% of the dataset was partitioned into the train set and the remaining 20% was reserved for the test set. This data table will be visualized into graphs and charts to further study its features. Thereafter, knn, random forest and support vector machine was adopted to model ratings of these beauty products.

## Data Visulization

```{r Download and prepare dataset, echo=FALSE, message=FALSE}
#Download packages if needed
if (!require(caret)) install.packages('caret')
if (!require(tidyverse)) install.packages('tidyverse')
if (!require(readr)) install.packages('readr')
if (!require(dplyr)) install.packages('dplyr')
if (!require(ggplot2)) install.packages('ggplot2')

#Load packages
library("caret")
library("tidyverse")
library("readr")
library("dplyr")
library("ggplot2")

#Import dataset
reviews <- read_csv("Data/sephora_website_dataset.csv")

#Remove unnecessary columns. Remaining columns should be predictors and rating/name only.
reviews <- reviews |> 
  subset(select = -c(id, details, how_to_use, ingredients, options, limited_time_offer, size, MarketingFlags, MarketingFlags_content, URL))

#Adjust each class of predictors
reviews <- reviews |>
  mutate (rating = as.factor(rating),
          brand = as.factor(brand),
          category = as.factor(category),
          online_only = as.factor(online_only),
          exclusive = as.factor(exclusive),
          limited_edition = as.factor(limited_edition))
```

Even though the dataset is polished for machine learning and comes with clean values, the dataset was tailored and attuned to fit the needs of this project. Columns including ingredients and size that are not useful for the prediction of ratings were removed. Limited time offer was also deleted as only three products were indeed offered on a limited time basis. The remaining columns, or predictors, that will be utilized to predict ratings are the following: brand, category, number of reviews, love, price, value price, online only, exclusive, and limited edition. The name column will be kept to distinguish each item.

```{r Overview of dataset, echo=FALSE, include = FALSE}
#Number of rows and columns
num_Rows <- nrow(reviews)
num_Cols <- ncol(reviews)
#Number of brands
num_Brands <- n_distinct(reviews$brand)
#Number of categories
num_Categories <- n_distinct(reviews$category)
```

There are `r num_Rows` rows (reviews) and `r num_Cols` columns (9 predictors, 1 rating, 1 name). The dataset comprises `r num_Brands` brands and `r num_Categories` categories. These statistics provide an indication of the substantial volume and variation of data that must be processed.

The reviews dataset now looks like such:
```{r Preview of dataset, echo=FALSE}
#Header of reviews
head(reviews)
```

The brand column contains the names of the brands each items are from. The category column groups the products into categories such as perfume, face masks or shampoo. The number of reviews column contains the number of reviews each product has. The love column counts how many customers bookmarked an item for potential future purchase. The price value shows the original product price while value price is the final value of the product after discounts. Online only, exclusive and limited edition are factor columns that are either 1 or 0. If the column name applies to an item, that item is a 1 and a 0 if not so. For example, if an item is exclusive only on Sephora, that item is a 1 in the exclusive column. Most importantly, the ratings column is also of a factor class with the following levels: 1, 1.5, 2, 2.5, 3, 3.5, 4.5, and 5. 5 indicates that customers were extremely satified with the product while 1 is left by a customer to express discontent and disappointment.

```{r Number of NAs, echo=FALSE}
#Number of NAs
str(sapply(reviews, function(x) which(is.na(x))))
```

As such, there aren't any missing values in the final dataset and is ready to be visuzlied and modeled.

```{r Number of ratings bar plot, echo=FALSE, out.width="65%"}
#Number of ratings bar plot
reviews |> ggplot(aes(rating)) + geom_bar() +
  labs(title = "Number of Ratings")
```

The plot illustrates the overall distribution of the total number of ratings, with the mode situated high up approximately between 4 and 4.5.


```{r love plot, echo=FALSE, out.width="65%"}
#Number of loves bar plot
reviews |> ggplot(aes(rating, love)) + geom_col() + 
  labs(title = "Number of loves and Their Mean Ratings",
       x = "Ratings",
       y = "Number of Loves")
```

The plot describes the total number of loves for rating class. The mode is located again at 4\~4.5.

```{r Top 10 Most loved product rating bar plot, echo = FALSE, out.width="65%"}
#Most loved product rating bar plot
reviews |> 
  arrange(desc(love)) |>
  slice(1:10) |>
  ggplot() +
  geom_col(aes(x = reorder(name, -love), y = love)) +
  geom_point(aes(x = reorder(name, -love), y = as.numeric(as.character(rating))*260000), color = "orange", size = 3.5) +
  scale_y_continuous(name = "Number of Loves", sec.axis = sec_axis( ~ ./260000, name = "Rating")) +
  labs(title = "Top 10 Most Loved Products",
       x = "Product") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

The most loved beauty products were consistently rated at 4 or higher which is suggestive of a greater correlation between these two variables.

```{r price/value price plot, echo=FALSE, out.width="65%", warning=FALSE}
#Price versus rating line plot
mean_price_rating <- reviews |>
  group_by(rating) |>
  summarise(mean_price = mean(price), mean_value_price = mean(value_price)) |>
  ungroup() |>
  pivot_longer(cols=c("mean_price", "mean_value_price"),
               names_to = "price_value_price",
               values_to = "price")

mean_price_rating |> ggplot(aes(price, as.numeric(as.character(rating)), color = price_value_price)) + 
  geom_line() +
  labs(title = "Price and Their Mean Rating",
       x = "Price",
       y = "Rating") +
  scale_color_manual(name = "Price or Value Price", 
                     values = c("red", "blue"))
```

The price plots tell a similar story as well with a similar distribution and a peak at once again 4\~4.5 stars. Price and value price both seem to have a similar relationship with ratings as well.

```{r Top 10 Most expensive product rating bar plot, echo=FALSE, out.width="65%"}
#Most expensive product rating bar plot
reviews |> arrange(desc(price)) |>
  slice(1:10) |>
  ggplot() +
  geom_col(aes(x=reorder(name, -price), y = price)) +
  geom_point(aes(x=reorder(name, -price), y=as.numeric(as.character(rating))*110), color="orange", size=3.5) +
  scale_y_continuous(name = "Price ($)", sec.axis = sec_axis( ~ ./110, name = "Rating")) +
  labs(title = "Top 10 Most Expensive Products",
       x = "Product") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 7))
```

In contrast to the top 10 most loved products, a consistent high rating could not be observed as only one product was rated 4.5 and the rest were rated below 4.

```{r marketing plot, echo=FALSE, warning=FALSE, out.width="80%"}
#Calculate means for each special offer
online_only_mean <- reviews |> 
  group_by(online_only) |>
  summarise(only_online = mean(as.integer(as.character(rating))))

exclusive_mean <- reviews |>
  group_by(exclusive) |>
  summarise(exclusive = mean(as.integer(as.character(rating))))

limited_edition_mean <- reviews |>
  group_by(limited_edition) |>
  summarise(limited_edition = mean(as.integer(as.character(rating))))

#Combine means into one data frame
special_offer <- 
  bind_cols(online_only_mean, exclusive_mean, limited_edition_mean) |>
  pivot_longer(cols = !"online_only", names_to = "SpecialOffer", values_to = "Yes")

#Special offers plot
special_offer |>
  ggplot(aes(SpecialOffer, Yes, fill = online_only)) +
  geom_col() +
  facet_wrap(~online_only) +
  labs(title = "Special Offers and Their Mean Rating",
       y = "Rating",
       fill = "Is there a special offer?") +
  scale_fill_discrete(labels = c("No", "Yes"))
```

The bar graph above depicts the relationship between special promotions and ratings. Counter-intuitively, the ratings were higher when the special promotion was not available.

```{r brand plot, echo=FALSE, out.width="65%"}
#Brand rating bar graph
mean_ratings_brands <- reviews |>
  group_by(brand) |>
  summarise(mean_rating = mean(as.integer(as.character(rating))), num_rating = sum(number_of_reviews)) |>
  ungroup()

mean_ratings_brands |>
  ggplot() + 
  geom_col(aes(x = reorder(brand, mean_rating), y = mean_rating)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, size = 1)) +
  labs(title = "Brands and Their Mean rating",
       x = "Brand",
       y = "Rating")
```

This plot helps us visualize how each brands were rated according to customers.

```{r top 10 brand plot, echo=FALSE, out.width="65%"}
#Brand rating bar graph (against number of reviews) - top 10
top_brands <- mean_ratings_brands |>
  arrange(desc(mean_rating)) |>
  slice(1:10)

top_brands |>
  ggplot() +
  geom_col(aes(x = reorder(brand, -mean_rating), y = mean_rating)) +
  geom_point(aes(x = reorder(brand, -mean_rating), y = num_rating/130), color = "orange", size = 3.5) +
  scale_y_continuous(name = "Mean Rating", sec.axis = sec_axis( ~ .*130, name = "Number of Reviews")) +
  theme(axis.text.x = element_text(angle = 50, hjust = 1, size = 10)) +
  labs(title = "Top 10 Brands with Highest Ratings",
       x = "Brand",
       y = "Rating")
```

In a similar vein, this plot zooms into the top 10 brands with the highest mean ratings were ranked along with the number of reviews they received each. The top four brands all had perfect ratings but Fable & Mane only received 18 reviews while Aether Beauty had 452.

```{r category plot, echo=FALSE, out.width="65%"}
#Category rating bar graph (against number of reviws) - top 10
mean_ratings_category <- reviews |>
  group_by(category) |>
  summarise(mean_rating = mean(as.integer(as.character(rating))), num_rating = sum(number_of_reviews)) |>
  ungroup() |>
  arrange(desc(mean_rating)) |>
  slice(1:10)

mean_ratings_category |>
  ggplot() +
  geom_col(aes(x = reorder(category, -mean_rating), y = mean_rating)) +
  geom_point(aes(x = reorder(category, -mean_rating), y = num_rating/2800), color = "orange", size = 3.5) +
  scale_y_continuous(name = "Mean Rating", sec.axis = sec_axis( ~ .*2800, name = "Number of Reviews")) +
  theme(axis.text.x = element_text(angle = 50, hjust = 1, size = 10)) +
  labs(title = "Top 10 Categories with Highest Ratings",
       x = "Category",
       y = "Rating")
```

Cologne ranked second with an impressive rating of 4.34 while also being fairly popular with 13635 reviews. Though Lip Shadow Brush came in first place, it seems to be a niche category with only 20 reviews.

```{r prepare data}
#Set seed and partition into train/test sets
reviews <- reviews |> mutate(brand = str_replace(reviews$brand, "SEPHORA COLLECTION", "'Sephora Collection'"))

set.seed(3)
test_ind <- createDataPartition(reviews$rating, times = 1, p = 0.2, list = FALSE)
test_set <- reviews[test_ind,]
train_set <- reviews[-test_ind,]

#Remove rows that are unique to the training set
unmatched_brand <- anti_join(train_set, test_set, by = "brand")
unmatched_category <- anti_join(train_set, test_set, by = "category")

train_set <- train_set[-(which(train_set$brand %in% unmatched_brand$brand)),]
train_set <- train_set[-(which(train_set$category %in% unmatched_category$category)),]

#Remove rows that are unique to the test set
unmatched_brand_test <- anti_join(test_set, train_set, by = "brand")
unmatched_category_test <- anti_join(test_set, train_set, by = "category")

test_set <- test_set[-(which(test_set$brand %in% unmatched_brand_test$brand)),]
test_set <- test_set[-(which(test_set$category %in% unmatched_category_test$category)),]
```

## Model/Anlaysis

The dataset was divided into a training set and a test set to evaluate the models performance and to avoid over-fitting. A seed value of two was assigned to ensure the reproducibility of the R code.

### KNN Model

```{r parameters}
#Set parameters for models
control <- trainControl(method = "cv", number = 10)
```

```{r knn model, warning=FALSE}
#Model 1 - KNN
model_knn <- train(rating ~ brand + category + number_of_reviews + love + price + value_price + online_only + exclusive + limited_edition, 
                   method = "knn", 
                   data = train_set,
                   trControl = control,
                   tuneLength = 10)

model_knn$results
accuracy_knn <- confusionMatrix(predict(model_knn, test_set), test_set$rating)$overall["Accuracy"]
accuracy_knn
accuracy_list <- tibble(model = "KNN", accuracy = accuracy_knn)
```

The knn model yielded a disappointing accuracy of `r accuracy_knn`.

### Random Forest Model

```{r random forest model, warning=FALSE}
#Model 2 - Random Forest
#This model may take a few minutes to run.
model_rf <- train(rating ~ brand + category + number_of_reviews + love + price + value_price + online_only + exclusive + limited_edition, 
                  data = train_set,
                  trControl = control,
                  method = "rf")

model_rf$results
accuracy_rf <- confusionMatrix(predict(model_rf, test_set), test_set$rating)$overall["Accuracy"]
accuracy_rf
accuracy_list <- accuracy_list |> add_row(model = "RF", accuracy = accuracy_rf)
```

The random forest model fared better at an accuracy of `r accuracy_rf`.

```{r support vector machine model, warning=FALSE}
#Model 3 - Support Vector Machine
#This model may take a few minutes to run.
model_svm <- train(rating ~ brand + category + number_of_reviews + love + price + value_price + online_only + exclusive + limited_edition, 
                  data = train_set,
                  trControl = control,
                  method = "svmRadial")

model_svm$results
accuracy_svm <- confusionMatrix(predict(model_svm, test_set), test_set$rating)$overall["Accuracy"]
accuracy_svm
accuracy_list <- accuracy_list |> add_row(model = "svm", accuracy = accuracy_svm)
```

The accuracy for the support vector machine model is `r accuracy_svm`.

## Result

```{r accuracy list, echo=FALSE}
accuracy_list
```

The cumulative table concludes that the random forest model is superior algorithm when it come to accuracy in predicting ratings compared to other models.

## Conclusion

This report explored the Sephora product dataset and implemented various non-linear algorithms for rating prediction. This public dataset was first studied and dissected the given predictors before priming the table for data training. The remaining columns were visualized onto graphs, illuminating their complexities. The seemingly unrelated nature of variables observed during this step of the process could have served as cautionary signs that the chosen features may not be strong predictors of customer ratings. In addition, computational limitations during this study restricted the exploration of more complex models. All in all, the accuracy of these two models are underperforming and suboptimal. We recommend future research to explore the relationships between the chosen variables and customer ratings in more detail. This could involve feature engineering to create new features or investigating the use of more advanced machine learning techniques. Despite the underperformance of the models in this study, this report serves to inform other data scientists about the potential of this dataset and to promote a deeper understanding of consumer behavior in the beauty product market.

Credits to @alharbi_sephora_nodate, @chen_impact_2022 and @rafael_advanced_2019 for providing the data set and further context throughout the report.

## References
